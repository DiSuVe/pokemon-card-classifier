{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-01-27T10:08:42.775172Z",
     "start_time": "2025-01-27T10:08:42.771700Z"
    }
   },
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from torchvision.models import ResNet18_Weights\n",
    "from PIL import Image"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Predicted Text + Type Icon",
   "id": "8b1503faf4ceb70e"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T10:08:42.827732Z",
     "start_time": "2025-01-27T10:08:42.819695Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def draw_text_with_icon(frame, text, icon_path, x, y, text_color=(0, 255, 0)):\n",
    "    font = cv2.FONT_HERSHEY_DUPLEX\n",
    "    font_scale = 0.9\n",
    "    thickness = 1\n",
    "\n",
    "    # Drawing text plus resizing it\n",
    "    cv2.putText(frame, text, (x, y), font, font_scale, text_color, thickness)\n",
    "    text_size, _ = cv2.getTextSize(text, font, font_scale, thickness)\n",
    "    text_width, text_height = text_size\n",
    "\n",
    "    # Type icons 30x30\n",
    "    icon = cv2.imread(icon_path)\n",
    "    if icon is None:\n",
    "        return\n",
    "    icon_w, icon_h = 30, 30\n",
    "    icon = cv2.resize(icon, (icon_w, icon_h))\n",
    "    # icon 10px to the right of the predicted text\n",
    "    offset_x = x + text_width + 10\n",
    "    offset_y = y - icon_h + 5\n",
    "\n",
    "    frame_h, frame_w, _ = frame.shape\n",
    "    if offset_x < 0: offset_x = 0\n",
    "    if offset_y < 0: offset_y = 0\n",
    "    if offset_x + icon_w > frame_w or offset_y + icon_h > frame_h:\n",
    "        return\n",
    "\n",
    "    roi = frame[offset_y:offset_y+icon_h, offset_x:offset_x+icon_w]\n",
    "    icon_gray = cv2.cvtColor(icon, cv2.COLOR_BGR2GRAY)\n",
    "    _, mask = cv2.threshold(icon_gray, 1, 255, cv2.THRESH_BINARY)\n",
    "    roi[mask == 255] = icon[mask == 255]"
   ],
   "id": "c4976ba10d5c8550",
   "outputs": [],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Card detection",
   "id": "5c8842a319e092b2"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T10:08:42.844102Z",
     "start_time": "2025-01-27T10:08:42.835507Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def find_card_roi(frame):\n",
    "    # Grayscaling, blurring, and detection of canny edges\n",
    "    gray_img = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    gray_img = cv2.GaussianBlur(gray_img, (5, 5), 0)\n",
    "    edges = cv2.Canny(gray_img, 60, 155)\n",
    "\n",
    "    # Detecting external contours\n",
    "    contours, _ = cv2.findContours(edges, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "    if not contours:\n",
    "        return None, None\n",
    "    # Sorting them to get the largest one\n",
    "    contours = sorted(contours, key=cv2.contourArea, reverse=True)\n",
    "\n",
    "    for cnt in contours:\n",
    "        peri = cv2.arcLength(cnt, True)\n",
    "        approx = cv2.approxPolyDP(cnt, 0.02 * peri, True)\n",
    "\n",
    "        if len(approx) == 4:\n",
    "            x, y, w, h = cv2.boundingRect(approx) # The 4 corner polygon\n",
    "\n",
    "            # 6.3cm, 8.8cm --> 1:1.4\n",
    "            aspect_ratio = float(w) / float(h) if h != 0 else 0\n",
    "            if 0.65 < aspect_ratio < 0.75:\n",
    "                card_roi = frame[y : y + h, x : x + w] # The ROI to work with\n",
    "                return card_roi, (x, y, w, h)\n",
    "    return None, None"
   ],
   "id": "17caa080e943a467",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T10:08:42.859111Z",
     "start_time": "2025-01-27T10:08:42.851223Z"
    }
   },
   "cell_type": "code",
   "source": [
    "unique_types = ['Darkness', 'Colorless', 'Grass', 'Water', 'Metal', \n",
    "                'Psychic', 'Lightning', 'Dragon', 'Fire', 'Fighting', \n",
    "                'Fairy']\n",
    "\n",
    "idx_to_type = {i: t for i, t in enumerate(unique_types)}\n",
    "\n",
    "type_icons = {'Darkness': 'tcg_symbols/Darkness.png', \n",
    "              'Colorless': 'tcg_symbols/Colorless.png', \n",
    "              'Grass': 'tcg_symbols/Grass.png', \n",
    "              'Water': 'tcg_symbols/Water.png', \n",
    "              'Metal': 'tcg_symbols/Metal.png', \n",
    "              'Psychic': 'tcg_symbols/Psychic.png', \n",
    "              'Lightning': 'tcg_symbols/Lightning.png', \n",
    "              'Dragon': 'tcg_symbols/Dragon.png', \n",
    "              'Fire': 'tcg_symbols/Fire.png', \n",
    "              'Fighting': 'tcg_symbols/Fighting.png', \n",
    "              'Fairy': 'tcg_symbols/Fairy.png'}"
   ],
   "id": "eba731d0700659ae",
   "outputs": [],
   "execution_count": 12
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Loading the model",
   "id": "a0f9c9b87f36946b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T10:08:43.073002Z",
     "start_time": "2025-01-27T10:08:42.880521Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "in_features = model.fc.in_features\n",
    "model.fc = nn.Linear(in_features, len(unique_types))\n",
    "\n",
    "model.load_state_dict(torch.load('pokemon_card_classifier.pth', \n",
    "                                 map_location='cpu', \n",
    "                                 weights_only=True)) # big warning if this is set to default\n",
    "model.eval()"
   ],
   "id": "a31717dd85bbd416",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=11, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 13
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Preprocessing Transforms",
   "id": "52b8da558b1cde98"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T10:08:43.078034Z",
     "start_time": "2025-01-27T10:08:43.073002Z"
    }
   },
   "cell_type": "code",
   "source": [
    "mean = [0.485, 0.456, 0.406]\n",
    "std = [0.229, 0.224, 0.225]\n",
    "transform = transforms.Compose([transforms.Resize((224, 224)), \n",
    "                                transforms.ToTensor(), \n",
    "                                transforms.Normalize(mean, std)])"
   ],
   "id": "1d032ebda501c1cd",
   "outputs": [],
   "execution_count": 14
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Video Capture",
   "id": "1d09a35b1d704779"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T10:08:43.271203Z",
     "start_time": "2025-01-27T10:08:43.078034Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# You can use any IP video stream app\n",
    "cap = cv2.VideoCapture('http://192.168.0.247:8080/video')\n",
    "if not cap.isOpened():\n",
    "    print('Can\\'t access video/stream')\n",
    "    exit()"
   ],
   "id": "ae6a895dd54b5001",
   "outputs": [],
   "execution_count": 15
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "## Detection\n",
    "Best results are achieved using cold natural light during the morning and using a black background. Results under sunlight or warm lights are poor at best!\n",
    "\n",
    "Also, huge thanks to this person: https://stackoverflow.com/questions/60895940/why-does-opencv-returns-a-false-ret-frame-cap-read"
   ],
   "id": "53fb7c183c3060c3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-27T10:09:30.777548Z",
     "start_time": "2025-01-27T10:08:43.271203Z"
    }
   },
   "cell_type": "code",
   "source": [
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print('Can\\'t access video stream')\n",
    "        break\n",
    "    # Finding the ROI\n",
    "    card_roi, box = find_card_roi(frame)\n",
    "    predicted_type = None\n",
    "\n",
    "    if card_roi is not None:\n",
    "        pil_roi = Image.fromarray(cv2.cvtColor(card_roi, cv2.COLOR_BGR2RGB))\n",
    "        input_tensor = transform(pil_roi).unsqueeze(0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            outputs = model(input_tensor)\n",
    "        _, predicted_idx = torch.max(outputs, 1)\n",
    "        predicted_type = idx_to_type[predicted_idx.item()]\n",
    "        # The box plus text\n",
    "        (x, y, w, h) = box\n",
    "        cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)\n",
    "        \n",
    "        text_str = f'Type: {predicted_type}'\n",
    "        icon_path = type_icons.get(predicted_type, None)\n",
    "        # text position\n",
    "        text_x = x\n",
    "        text_y = y - 10\n",
    "        if text_y < 20:\n",
    "            text_y = y + h + 30 # below if no room above\n",
    "\n",
    "        if icon_path is not None:\n",
    "            draw_text_with_icon(frame, text_str, icon_path, text_x, text_y, text_color=(0, 255, 0))\n",
    "        else:\n",
    "            cv2.putText(frame, text_str, (text_x, text_y),\n",
    "                        cv2.FONT_HERSHEY_DUPLEX, 0.9, (0, 255, 0), 2)\n",
    "    else:\n",
    "        cv2.putText(frame, 'No card detected', (10, 30),\n",
    "                    cv2.FONT_HERSHEY_DUPLEX, 1, (0, 0, 255), 1)\n",
    "\n",
    "    cv2.imshow('DL Project - Pkmn TCG Card Classifier', frame)\n",
    "    \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ],
   "id": "c090c553adfd7d53",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Can't access video stream\n"
     ]
    }
   ],
   "execution_count": 16
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
